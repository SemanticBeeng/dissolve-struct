\documentclass[twoside,11pt]{article}


% JMLR Machine Learning Open Source Software papers:
% those are 4 pages plus references
% more details:
% http://www.jmlr.org/mloss/mloss-info.html


% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

\usepackage{jmlr2e}
\usepackage{hyperref}
\usepackage{xspace}
\usepackage{bm,color}
\usepackage{mathdots}
\usepackage{subcaption}
\usepackage{amsopn}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage[colorinlistoftodos,bordercolor=orange,backgroundcolor=orange!20,linecolor=orange,textsize=scriptsize]{todonotes}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\definecolor{darkgreen}{rgb}{0,.4,.2}
\definecolor{darkblue}{rgb}{.1,.2,.6}
\definecolor{brightblue}{rgb}{0,0.6,0.8}
\hypersetup{
  colorlinks=true,
  linkcolor=darkblue,
  citecolor=darkgreen,
  filecolor=darkblue,
  urlcolor=darkblue
}

% Definitions of handy macros can go here

\newcommand{\algname}{\textsc{Dissolve}$\,^{\textsf{\tiny struct}}$\xspace}
\newcommand{\svmstruct}{\textsc{SVM}$\,^{\textsf{\tiny struct}}$\xspace}
\newcommand{\cocoa}{\textsc{CoCoA}\xspace}
\newcommand{\cocoap}{\textsc{CoCoA$\!^{\bf \textbf{\footnotesize+}}$}\xspace}
\newcommand{\spark}{\textsc{Spark}\xspace}
\newcommand{\vectornorm}[1]{\left|\left|#1\right|\right|} 

\newcommand{\comment}[1]{}
\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}

\newcommand{\alphav}{\bm{\alpha}}
\newcommand{\xv}{{\bf x}}
\newcommand{\yv}{{\bf y}}

% cocoa stuff
\newcommand{\vc}[2]{#1^{(#2)}}
\newcommand{\vsubset}[2]{#1_{[#2]}}
\newcommand{\Ggk}{\mathcal{G}^{\sigma'}_k\hspace{-0.08em}}
\newcommand{\aggpar}{\gamma}

\DeclareMathOperator*{\E}{\rm E}
\newcommand{\simplex}{\Delta}

% general math
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\kroneckerdelta}[2]{\delta_{#2}(#1)}
\newcommand{\realnumbers}{\mathbb{R}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\transpose}{\mathsf{T}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}
\newcommand\SetOf[2]{\left\{#1\,\vphantom{#2}\right.\left|\vphantom{#1}\,#2\right\}}

%vectors
\newcommand{\id}{\mathbf{I}} % big i for identity
\newcommand{\ind}{\mathbf{1}} % indicator vectors
\newcommand{\0}{\mathbf{0}} % the origin
\newcommand{\unit}{\mathbf{e}} % unit basis vectors
\newcommand{\one}{\mathbf{1}} % all one vector

\newcommand{\bv}{\bm{b}}

% structured output prediction
\newcommand{\inputvar}{x}
\newcommand{\inputvarv}{\bm{\inputvar}}
\newcommand{\inputdomain}{\mathcal{X}}
\newcommand{\outputvar}{y}
\newcommand{\outputvarv}{\bm{\outputvar}}
\newcommand{\outputdomain}{\mathcal{Y}}
%\newcommand{\hiddenvar}{z}
%\newcommand{\hiddenvarv}{\bm{\hiddenvar}}
%\newcommand{\hiddendomain}{\mathcal{Z}}
\newcommand{\inputoutputdomain}{\mathcal{H}}
\newcommand{\featuremap}{\phi}
\newcommand{\featuremapv}{\bm{\featuremap}}
\newcommand{\featuremapdiff}{\psi}
\newcommand{\featuremapdiffv}{\bm{\featuremapdiff}}
\newcommand{\errorterm}{L}
\newcommand{\weight}{w}
\newcommand{\weightv}{\bm{\weight}}
\newcommand{\wv}{{\bm{\weight}}}
\newcommand{\dualvar}{\alpha}
\newcommand{\dualvarv}{\bm{\alpha}}
\newcommand{\kernelmatrix}{K}
\newcommand{\kernelmatrixv}{\bm{\kernelmatrix}}
\newcommand{\Lmax}{L_{\text{\tiny{max}}}}

% Frank-Wolfe
\newcommand{\sv}{\bm{s}}
\newcommand{\x}{{\bm{x}}} %not to be confused with SVM x
\newcommand{\y}{{\bm{y}}} %not to be confused with SVM y
\newcommand{\e}{{\bm{e}}} % appears in proof of linear convergence...
\newcommand{\stepsize}{\gamma}
\newcommand{\domain}{\mathcal{D}} %TODO: be careful!
%\newcommand{\CfTotal}{C_f^{\text{\tiny{prod}}}}
\newcommand{\CfTotal}{C_{\hspace{-0.1em}f}^\otimes}
\newcommand{\Cf}{C_{\hspace{-0.08em}f}}
\DeclareMathOperator{\approxLin}{\textsc{ApproxLinearMin}}
\DeclareMathOperator{\exactLin}{\textsc{LinearMin}}
\newcommand{\approxArgMin}{\operatornamewithlimits{[approx]\argmin}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\vv}{{\bm{v}}}
\newcommand{\ww}{{\bm{w}}}
\newcommand{\zz}{{\bm{z}}}
\newcommand{\mapprox}{\nu} % multiplicative approximation quality
\newcommand{\addFactor}{\tilde{\gamma}} % constant appearing in the additive approximatoin quality

\newcommand{\note}[1]{{\color{red}#1}}
\newcommand{\ignore}[1]{}


% Heading arguments are {volume}{year}{pages}{submitted}{published}{author-full-names}

\jmlrheading{1}{2015}{1-??}{1/15}{1/15}{Tribhuvanesh Orekondy, Martin Jaggi and Aurelien Lucchi}

% Short headings should be running head and authors last names

\ShortHeadings{Learning with Mixtures of Trees}{Orekondy, Jaggi and Lucchi}
\firstpageno{1}

\begin{document}

\title{\algname -- A Library for Distributed Structured Prediction}

\author{%
       \name Tribhuvanesh Orekondy \email torekond@student.ethz.ch  \\
       \addr ETH Zurich
       \AND
       \name Martin Jaggi \email jaggi@inf.ethz.ch \\
       \addr ETH Zurich
       \AND
       \name Aurelien Lucchi \email aurelien.lucchi@inf.ethz.ch  \\
       \addr ETH Zurich
       }
       

\editor{t.b.d.}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
This paper describes \algname, a modular and flexible
open source software package for distributed training of structured
prediction models, such as structured SVMs. 
Project website: \href{http://github.com/dalab/dissolve}{github.com/dalab/dissolve}.

We support a broad range of applications, and interfaces to scala, java and python. Our framework is empowered by the fault tolerant \spark computing platform, and automatically adopts to the existing tradeoffs of computation vs communication cost on real world systems. 
The proposed distributed algorithm combines the recent communication efficient \cocoa scheme \citep{Jaggi:2014vi,Ma:2015ti} with the state of the art primal-dual structured prediction solvers \citep{LacosteJulien:2013ue}, and improves further by adding some new ideas for caching oracle answers. 
The framework allows approximate inference, and provides a similar standard interface as \svmstruct for the user.
\end{abstract}

\begin{keywords}
  Structured Prediction, Structured SVM, Distributed Training
\end{keywords}

\section{Introduction}

Structured prediction has gained a lot of popularity over the past few years due to its ability to process structured objects such as images or text documents.

The structured support vector machine (SSVM) is a particularly successful variant of this approach that can be optimized in various ways, including cutting-plane methods, stochastic gradient descent, or a primal-dual scheme such as \citep{LacosteJulien:2013ue}. 

The main contribution of our work is to extend the primal-dual \cocoap framework~\citep{Jaggi:2014vi,Ma:2015ti} also to the structured SVM case, and combine it with BCFW \citep{LacosteJulien:2013ue} used as a local solver.

{\noindent \em Remainder omitted in this sample. See http://www.jmlr.org/papers/ for full paper.}


%
\section{Structured SVM formulation}

A structured model predicts the labeling $\yv$ for a given input $\xv$ by maximizing some score function
$S_\wv:\mathcal{X} \times \mathcal{Y} \rightarrow \mathbb{R}$,
i.e.,
%
\begin{equation}
\label{eq:inference}
\hat{\yv} = \argmax_{\yv \in \mathcal{Y}} S_\wv(Y) = \argmax_{Y \in \mathcal{Y}} \wv^T\Psi(\xv,\yv),
\end{equation}
%
where $\wv$ are the model parameters and $\Psi(\xv,\yv)$ is the \emph{feature map} corresponding to the input $\xv$ and the labeling $\yv$.


Given a set of $n$ training examples $\dataset=\{(\xv_i,\yv_i), \dots, (\xv_n, \yv_n)\}$ where $\xv_i \in \mathcal{X}$ and $\yv_i \in \mathcal{Y}$ is the associated labeling, 
the learning task consists in finding model parameters $\wv$ that achieve low empirical loss subject to some regularization. In other words, we seek
%
\begin{align}
\label{eq:ssvm_primal}
%\wv^* &= \argmin_\wv \mathcal{L}(\dataset, \wv) \nonumber \\
\wv^* = \argmin_{\wv} \sum_{n=1}^n \ell(\xv_i, \yv_i, \wv) + R(\wv),
\end{align}
%
where $\ell$ is the \emph{surrogate loss} function,
a quantity that is usually related to and often upper-bounds the training error, 
and $R(\wv)$ is the regularizer (such as the L2 norm of $\wv$)
that helps prevent overfitting. 
The most common choice of $\ell$ is the hinge loss, as used in~\citep{Taskar:2003tt,Tsochantaridis:2005ww}, which is defined as
\begin{equation}
\label{eq:hinge-loss}
l(\yv_i, \yv^*_\wv, \wv) = [S_\wv(\yv^*_\wv) + \Delta(\yv_i, \yv^*_\wv) - S_\wv(\yv_i)]_+
\end{equation}


The most popular method to solve problems of the form~\eqref{eq:ssvm_primal}
is the stochastic subgradient method (SGD)~\citep{Ratliff:2007ti,ShalevShwartz:2010cg}. Although this method has been quite successful it requires tuning parameters to achieve good performance. An experimental comparison of our proposed approach with distributed variants of SGD is provided in Section~\ref{sec:experiments} below.


The Lagrange dual of the above $n$-slack-formulation (\ref{eq:ssvm_primal}) has $m := \sum_i |\outputdomain_i|$ variables or potential `support vectors'.
Writing $\dualvar_i(\outputvarv)$ for the dual variable associated with the training example $i$ and potential output $\outputvarv \in \outputdomain_i$, the dual problem is given by
\begin{align}
    \label{eq:ssvm_dual} % or do we prefer to write it as a maximization?
    \min_{\substack{ \dualvarv\in\R^{m} \\  \dualvarv \geq 0}} \quad  f(\dualvarv) \;:=&  \;\;
    \frac{\lambda}{2}
    \big\| A\dualvarv \big\|^2
    - \bv^T\dualvarv
    \\[-2mm]
    \text{s.t.} \quad &  \;
      \textstyle\sum_{\outputvarv \in \outputdomain_i}  \dualvar_i(\outputvarv) = 1 ~~~\forall i\in[n] \ , \notag 
\end{align}
where the matrix $A\in\R^{d\times m}$ consists of the $m$ columns $A := \SetOf{\frac1{\lambda n} \featuremapdiffv_i(\outputvarv) \in\R^d}{i\in[n],\outputvarv \in \outputdomain_i}$, and the vector $\bv \in \R^m$ is given by 
$\bv:= \left(\frac1n \errorterm_i(\outputvarv) \right)$$_{i\in[n],\outputvarv\in\outputdomain_i}$. %TODO: replace n by N
Given a dual variable vector~$\dualvarv$, we can use the Karush-Kuhn-Tucker optimality conditions  to obtain the corresponding primal variables~$
\wv = A\dualvarv  = \sum_{i,\,\outputvarv \in \outputdomain_i} \dualvar_i(\outputvarv)  \frac{\featuremapdiffv_i(\outputvarv)}{\lambda n}
$, see Appendix~\ref{sec:app_duals}.
The gradient of $f$ then takes the simple form $\nabla f(\dualvarv) = \lambda A^TA\dualvarv - \bv = \lambda A^T\wv - \bv$; its \mbox{$(i,\outputvarv)$-th} component is $-\frac{1}{n} H_i(\outputvarv; \wv)$, cf.~\eqref{eq:subproblem_loss_augm}. 
Finally, note that the domain $\domain \subset \R^m$ of~\eqref{eq:ssvm_dual} is the product of $n$ probability simplices, $\domain := \simplex_{|\outputdomain_1|}\times\mathellipsis\times\simplex_{|\outputdomain_n|}$.


%
\section{Distributed Algorithm}


%\comment{
%This approach exploits the associated conjugate \emph{dual} problem of \eqref{eq:sdcaPrimal} defined over one dual variable per each example in
%the training set.
%\begin{equation}
%    \label{eq:sdcaDual}
%    \max_{\alphav \in \R^n} \quad \Big[ \ 
%    D(\alphav) := - \frac{\lambda}{2} \norm{ A\alphav }^2
%    - \frac1n \sum_{i=1}^n \ell_i^*(-\alpha_i) \ \Big],
%\end{equation}
%where $\ell_i^*$ is the conjugate (Fenchel dual) of the loss function
%$\ell_i$%
%, and the data matrix $A\in\R^{d\times n}$ collects the (normalized) data
%examples $A_i := \frac{1}{\lambda n} X^i$ in its columns. The duality comes with the convenient mapping from dual to primal variables
%$\wv(\alphav) := A\alphav$ as given by the optimality
%conditions~\cite{ShalevShwartz:2013wl}.
%For any configuration of the dual variables $\alphav$, we have the duality gap
%defined as $P(\wv(\alphav)) - D(\alphav)$. This gap is a computable certificate of
%the approximation quality to the unknown true optimum $P(\wv^*) = D(\alphav^*)$,
%and therefore serves as a useful stopping criteria as well as a way to automatically set the stepsize. We refer the reader to~\cite{Jaggi:2014vi} for further details.
%}

\paragraph{Local Subproblem per Machine}
Following the idea in \citep{Ma:2015ti}, we can define a data-local subproblem of the original dual optimization problem \eqref{eq:ssvm_dual}, which can be solved on machine~$k$ and only requires accessing (and decoding) data examples which are already available locally, i.e., examples with $i\in\mathcal{P}_k$. More formally, each machine $k$ is assigned the following local subproblem, depending only on the previous shared primal vector $\wv\in\R^d$, and the change in the local dual variables~$\alpha_i$ with $i\in\mathcal{P}_k$:
\begin{equation} 
\max_{\vsubset{\Delta \alphav}{k}\in\R^{n}} \ %TODO: could be interpreted a bit ambiguious, since these vectors live in R^n, but we only care about one coordinate block
\Ggk(  \vsubset{\Delta \alphav}{k}; \wv, \vsubset{\alphav}{k})
\end{equation} 
where \begin{align} 
&\Ggk(  \vsubset{\Delta \alphav}{k}; \wv, \vsubset{\alphav}{k})
:=
-\frac1n\sum_{i \in \mathcal{P}_k} 
\ell_i^*(-\alpha_i - (\vsubset{\Delta \alphav}{k})_i)
\nonumber
\\
&\hspace{-2mm} 
- \frac1K 
\frac{\lambda}{2}
\|\wv\|^2
-\frac1n
\wv^T A \vsubset{\Delta \alphav}{k}
%\nonumber
%\\
%&\hspace{15mm}  
- \frac\lambda2
 \sigma'  \Big\|\frac1{\lambda n} A \vsubset{\Delta \alphav}{k}\Big\|^2
 \label{eq:subproblem}
\end{align}
note that $\ell_i^*$ here is a simplex-constraint.
\todo[inline]{write a few words here that this is really an extension of the primal-dual structure assumed in the \cocoa papers. those have just allowed $\ell_i^*$'s depending on a single dual variable. here we have simplex blocks of variables, one per $\ell_i^*$. one of the newer SDCA papers also has this generalized duality structure}

\paragraph{Algorithm:}
Two variants essentially, see discussion in \citep{Ma:2015ti}
\begin{itemize}
\item \cocoa Averaging, $\aggpar := \frac1K$, using the safe subproblem parameter $\sigma':=1$
\item \cocoap Adding, $\aggpar := 1$, using the safe subproblem parameter$\sigma':=K$ 
\end{itemize}

\begin{algorithm}[h]
\caption{\cocoap Framework}
\label{alg:cocoa}

\begin{algorithmic}[1]
\STATE {\bf Input:} Datapoints $A$ distributed according to partition $\{\mathcal{P}_k\}_{k=1}^K$.
Aggregation parameter $\aggpar\!\in\!(0,1]$, 
subproblem parameter $\sigma'$ for the local subproblems
$\Ggk(  \vsubset{\Delta \alphav}{k}; \wv, \vsubset{\alphav}{k})$ for each $k\in[K]$.\\
Starting point $\vc{\alphav}{0} := \0 \in \R^n$, $\vc{\wv}{0}:=\0\in \R^d$.
\FOR {$t = 0, 1, 2, \dots $}
  \FOR {$k \in \{1,2,\dots,K\}$ {\bf in parallel over computers}}
     \STATE call the local solver, computing
     a $\Theta$-approximate solution 
     $\vsubset{\Delta \alphav}{k}$   
        of  the local subproblem \eqref{eq:subproblem} 
     \STATE update $\vsubset{\vc{\alphav}{t+1}}{k} := \vsubset{\vc{\alphav}{t}}{k} + \aggpar \, \vsubset{\Delta \alphav}{k}$
     \STATE return $\Delta \wv_k :=\frac1{\lambda n} A \vsubset{\Delta \alphav}{k}$ %TODO: think again about the most user friendly interface for local solver: should the local solver only return delta alpha, or its delta \wv as well?
  \ENDFOR
  \STATE reduce\vspace{-6mm}
\begin{equation}\label{eq:primalGlobalUpdate}\vspace{-1mm}
\vc{\wv}{t+1}  := \vc{\wv}{t} +
  \aggpar \textstyle \sum_{k=1}^K \Delta \wv_k.
\end{equation}
\ENDFOR 
\end{algorithmic}
\end{algorithm}







%
\section{Software package}

The use of the \algname requires users to implement the following functions:
\begin{itemize}
\item The joint feature map $\Psi(X,Y)$ which encodes the input/output pairs.
\item The structured loss function $\Delta(Y_i,Y)$.
\item A maximization oracle which computes the most violating constraint by solving Eq. X.
\item A prediction function that computes $X$. This operation is usually performed with the maximization oracle.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[h]
\caption{Comparison of structured prediction software packages}
\label{tab:datasets}
   \begin{center}
      \begin{tabular}{l l l c c c c}
       \vspace{.25em}
    {\small\textbf{Package}} & {\small\textbf{Language}} & %
    {\small\textbf{License}} & \small\textbf{Distributed} & \multicolumn{3}{c}{\small\textbf{Models}} \\
    \hline
    & & & & ML & Chain & Graph \\
    \algname & Scala & ? & \checkmark & \xmark & \checkmark & \checkmark \\
    PyStruct & Python & BSD & \checkmark & \xmark & \checkmark & \checkmark \\
	SVM\textsuperscript{struct} & C++ & non-free & \checkmark & \xmark & \xmark & \xmark \\
	Dlib & C++ & boost & \checkmark & \xmark & \checkmark & \checkmark \\
	CRFsuite & C++ & BSD & \checkmark & \checkmark & \checkmark & \xmark \\
      \end{tabular}
   \end{center}\vspace{-2mm}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

TODO: Can we show a simple example like the pystruct paper?

\section{Experiments}\label{sec:experiments}

Run experiments on one or two standard structured prediction tasks.

\paragraph{Experiment 1:} 
scaling number of machines, on same dataset.

\paragraph{Experiment 2:}
cocoa+-bcfw vs standard distributed mini-batch SGD


(Compare to other frameworks... ? most are just single machine. could include to show more insights on our single machine performance as well)

%related work:
% for the different squared hinge loss objective: Multi-core Structural SVM Training \cite{Chang:2013ti}
% and distributed \cite{Lee:2015wq}


% Acknowledgements should go at the end, before appendices and references
\acks{We would like to thank Jan Deriu, Bettina Messmer, Thijs Vogels and Ruben Wolff for contributing to the code and discussions to improve readability.}


% Manual newpage inserted to improve layout of sample file - not
% needed in general before appendices/bibliography.

\newpage

\appendix
\section*{Appendix A.}
\label{app:theorem}

% Note: in this sample, the section number is hard-coded in. Following
% proper LaTeX conventions, it should properly be coded as a reference:

%In this appendix we prove the following theorem from
%Section~\ref{sec:textree-generalization}:

In this appendix we prove the following theorem from
Section~6.2:

\noindent
{\bf Theorem} {\it Let $u,v,w$ be discrete variables such that $v, w$ do
not co-occur with $u$ (i.e., $u\neq0\;\Rightarrow \;v=w=0$ in a given
dataset $\dataset$). Let $N_{v0},N_{w0}$ be the number of data points for
which $v=0, w=0$ respectively, and let $I_{uv},I_{uw}$ be the
respective empirical mutual information values based on the sample
$\dataset$. Then
\[
	N_{v0} \;>\; N_{w0}\;\;\Rightarrow\;\;I_{uv} \;\leq\;I_{uw}
\]
with equality only if $u$ is identically 0.} \hfill\BlackBox

\noindent
{\bf Proof}. We use the notation:
\[
P_v(i) \;=\;\frac{N_v^i}{N},\;\;\;i \neq 0;\;\;\;
P_{v0}\;\equiv\;P_v(0)\; = \;1 - \sum_{i\neq 0}P_v(i).
\]
These values represent the (empirical) probabilities of $v$
taking value $i\neq 0$ and 0 respectively.  Entropies will be denoted
by $H$. We aim to show that $\fracpartial{I_{uv}}{P_{v0}} < 0$....\\

{\noindent \em Remainder omitted in this sample. See http://www.jmlr.org/papers/ for full paper.}


\vskip 0.2in
\bibliography{references}

\end{document}
